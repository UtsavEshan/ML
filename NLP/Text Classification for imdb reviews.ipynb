{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc2af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed29cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading using sentiment140 for text classification\n",
    "#tfds dataset\n",
    "dataset, info = tfds.load('imdb_reviews',with_info=True,as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "172413b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 100\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ada261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "#tfds loads raw texts we need to vectorize the text to feed into our model\n",
    "\n",
    "#TextVectorization layers\n",
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))\n",
    "#encoder is now able to encode text to a matrix \n",
    "#unknwon vocabulary are replaced with a known token with no value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a4135f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "#Model development\n",
    "\n",
    "# input -> encoder -> embedding layer -> bidirectional lstm -> dense ->dense ->classification\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "#which layers support masking, masking allows the embedding layer to handle varying sequence lengths\n",
    "print([layer.supports_masking for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df5df68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 31s 103ms/step - loss: 0.6837 - accuracy: 0.5088 - val_loss: 0.5942 - val_accuracy: 0.6377\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.4848 - accuracy: 0.7538 - val_loss: 0.4331 - val_accuracy: 0.8293\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 38s 152ms/step - loss: 0.3978 - accuracy: 0.8180 - val_loss: 0.3760 - val_accuracy: 0.8400\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 37s 149ms/step - loss: 0.3572 - accuracy: 0.8442 - val_loss: 0.3506 - val_accuracy: 0.8510\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 37s 148ms/step - loss: 0.3360 - accuracy: 0.8563 - val_loss: 0.3385 - val_accuracy: 0.8477\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 38s 151ms/step - loss: 0.3208 - accuracy: 0.8655 - val_loss: 0.3213 - val_accuracy: 0.8600\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 37s 150ms/step - loss: 0.3115 - accuracy: 0.8665 - val_loss: 0.3237 - val_accuracy: 0.8537\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 38s 151ms/step - loss: 0.3038 - accuracy: 0.8732 - val_loss: 0.3150 - val_accuracy: 0.8673\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 38s 153ms/step - loss: 0.3020 - accuracy: 0.8743 - val_loss: 0.3160 - val_accuracy: 0.8637\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 38s 151ms/step - loss: 0.2995 - accuracy: 0.8752 - val_loss: 0.3278 - val_accuracy: 0.8487\n"
     ]
    }
   ],
   "source": [
    "#compile and training\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3ec4dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample_text = ('This was a great movie. Nolan is a really good director')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "if predictions[0]>0.5:\n",
    "    print(1)\n",
    "else:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250549a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
